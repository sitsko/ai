quarkus.http.port=${AI_APP_PORT}

quarkus.langchain4j.chat-model.provider = ${AI_MODEL_PROVIDER:openai}
quarkus.langchain4j.log-requests = true
quarkus.langchain4j.log-responses = true

# OpenAI Configuration
quarkus.langchain4j.openai.api-key = ${OPEN_AI_TOKEN}
quarkus.langchain4j.openai.timeout = 20s
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o-mini

# Ollama Configuration
quarkus.langchain4j.ollama.base-url = ${OLLAMA_BASE_URL:http://localhost:11434}



# observability
#quarkus.otel.logs.enabled=true
#quarkus.otel.traces.enabled=true